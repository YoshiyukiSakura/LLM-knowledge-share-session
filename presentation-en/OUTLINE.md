# Presentation Outline

## Current Structure (To Be Modified)

> Issue: Part 01 duplicated, uneven pacing, Transformer missing

---

## New Structure Plan

### Cover & Overview

| # | Slide | Topic Content | Status |
|---|-------|---------------|--------|
| 1 | Slide01Title | **Cover**: Deep Dive into Large Language Models | Keep |
| 2 | Slide02Overview | **Content Overview**: Update to new Part structure | Needs Change |

### Part 01: Understanding the World Through Rules

| # | Slide | Topic Content | Status |
|---|-------|---------------|--------|
| 3 | Slide03aRulesExamples | **Phenomenon**: Correspondences in daily life | Keep |
| 4 | Slide03bRulesAbstract | **Abstraction**: Transform into coordinates (x, y) | Keep |
| 5 | Slide03cRulesGraph | **Graph**: Derive y = x | Keep |
| 6 | Slide03dRulesText | **Summary**: The power and origin of rules | Keep |

### Part 02: Rule Transformations and Software Boundaries

| # | Slide | Topic Content | Status |
|---|-------|---------------|--------|
| 7 | Slide04aTransformExamples | **Phenomenon**: Degree/preference/comprehensive differences | Keep |
| 8 | Slide04bTransformAbstract | **Abstraction**: k (slope) and b (intercept) | Keep |
| 9 | Slide04cTransformGraph | **Graph**: Three transformation diagrams | Keep |
| 10 | Slide04dTransformText | **Summary**: y = kx + b | Keep |
| 11 | Slide04eSoftware | **Birth of Software**: Automation of point-like patterns (Symbolicism) | Moved (from 03e) |
| 12 | Slide04fConnectionism | **Connectionism**: Success and limitations of linear fitting | New |

### Part 03: Breaking Through Linear Boundaries

| # | Slide | Topic Content | Status |
|---|-------|---------------|--------|
| 13 | Slide05aLinearLimitGraph | **Linear Limitations - Graph**: Cannot fit curves | Keep |
| 14 | Slide05bLinearLimitText | **Linear Limitations - Summary**: Introducing activation functions | Keep |
| 15 | Slide06aActivationGraph | **Activation Functions - Graph**: Linear vs Non-linear | Keep |
| 16 | Slide06bActivationText | **Activation Functions - Summary**: ReLU/Sigmoid/Tanh | Keep |

### Part 04: From Neurons to Transformer

| # | Slide | Topic Content | Status |
|---|-------|---------------|--------|
| 16 | Slide07aNeuralNetwork | **Neural Network Basics**: Neuron = One transformation | Needs Change (split) |
| 17 | Slide07bDeepLearning | **Deep Learning**: Multi-layer stacking, function nesting | New |
| 18 | Slide07cAttention | **Attention Mechanism**: "Focus" on which words are important | New |
| 19 | Slide07dTransformer | **Transformer**: Self-Attention + Parallel computation | New |

### Part 05: Large Language Models

| # | Slide | Topic Content | Status |
|---|-------|---------------|--------|
| 20 | Slide08LLMEssence | **LLM Essence**: Super text completion machine | Keep |
| 21 | Slide08bTokenization | **Tokenization**: How text becomes numbers (optional) | New (optional) |
| 22 | Slide09LLMBoundary | **Capability Boundaries**: Strengths vs weaknesses | Keep |

### Part 06: Agent and Tool Calling

| # | Slide | Topic Content | Status |
|---|-------|---------------|--------|
| 23 | Slide10Agent | **Agent Analogy**: Engine + Shell = Product | Keep |
| 24 | Slide11AgentForms | **Agent Forms**: CLI / Web / API | Keep |
| 25 | Slide12FunctionCall | **Function Call**: Structured output | Keep |
| 26 | Slide13MCP | **MCP Protocol**: Unified tool calling | Keep |

### Part 07: Challenges and Summary

| # | Slide | Topic Content | Status |
|---|-------|---------------|--------|
| 27 | Slide14Challenges | **Current Challenges**: Context/Tool selection/Security | Keep |
| 28 | Slide15Summary | **Summary**: From rules to intelligence | Keep |
| 29 | Slide16Appendix | **Appendix**: Math problem analogy for Token completion | Keep |

---

## Modification Checklist

### 1. Structure Adjustments
- [x] Re-plan Part numbering (01-07)
- [x] Move Slide03eSoftware to the end of Part 02, rename to Slide04eSoftware
- [x] Update Slide02Overview topic list
- [x] Update PartLabel numbering for all Slides

### 2. New Slides (Part 04 Extension)
- [x] **Slide07bDeepLearning**: Deep Learning - How multi-layer neural networks stack
- [x] **Slide07cAttention**: Attention Mechanism - Explain "attention" with real-life examples
- [x] **Slide07dTransformer**: Transformer architecture diagram

### 3. Optional Additions
- [ ] **Slide08bTokenization**: Tokenization process (if time permits)

### 4. Existing Slides That Need Modification
- [x] Slide02Overview: Update 6 topics to new 7 Parts
- [x] Slide07NeuralNetwork: Split/simplify to Slide07aNeuralNetwork
- [x] Delete old files Slide03eSoftware.tsx, Slide07NeuralNetwork.tsx
